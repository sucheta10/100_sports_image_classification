# Import necessary libraries
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array
from tensorflow.keras.callbacks import EarlyStopping
import os

# Mount Google Drive (if using Google Colab)
from google.colab import drive
drive.mount('/content/drive')
# Define paths to your data
train_path = "/content/drive/My Drive/sports_classification/train"
validation_path = "/content/drive/My Drive/sports_classification/valid"
test_path = "/content/drive/My Drive/sports_classification/test"

# List all the categories in the training path
image_categories = os.listdir(train_path)

# Function to plot the first image from each category
def plot_images(image_categories):
    # Create a figure
    plt.figure(figsize=(12, 12)) # Set the figure size

    for i, category in enumerate(image_categories):
        # Load the first image in each category folder
        category_path = os.path.join(train_path, category)
        # List all files in the category folder
        image_files = os.listdir(category_path)
        # Get the path to the first image file in the category
        first_image_path = os.path.join(category_path, image_files[0])

        # Load the image and resize it to 150x150 pixels
        img = load_img(first_image_path, target_size=(150, 150))
        # Convert the image to an array and normalize pixel values
        img_arr = img_to_array(img) / 255.0  # Normalize pixel values
        # Create a subplot for the image
        plt.subplot(10, 10, i + 1)
        # Display the image
        plt.imshow(img_arr)
        # Set the title as the category name
        plt.title(category)
        # Turn off the axis
        plt.axis('off')

    plt.tight_layout()
    plt.show()

# Call the function to plot the images
plot_images(image_categories)
# Create ImageDataGenerator instances for train, validation, and test sets
train_datagen = ImageDataGenerator(rescale=1.0/255.0)
val_datagen = ImageDataGenerator(rescale=1.0/255.0)
test_datagen = ImageDataGenerator(rescale=1.0/255.0)

# Flow from directory for train set
train_generator = train_datagen.flow_from_directory(
    train_path,
    target_size=(150, 150),
    batch_size=32,
    class_mode='categorical')
# Flow from directory for validation set
val_generator = val_datagen.flow_from_directory(
    validation_path,
    target_size=(150, 150),
    batch_size=32,
    class_mode='categorical')
# Flow from directory for test set
test_generator = test_datagen.flow_from_directory(
    test_path,
    target_size=(150, 150),
    batch_size=32,
    class_mode='categorical')
# Print the class encodings done by the generators
class_map = {v: k for k, v in train_generator.class_indices.items()}
print("Class Map:", class_map)
# Build the sequential CNN model
model = Sequential()

# Add Convolutional and Pooling layers
model.add(Conv2D(filters=32, kernel_size=3, strides=1, padding='same', activation='relu', input_shape=(150, 150, 3)))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Conv2D(filters=64, kernel_size=3, strides=1, padding='same', activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Conv2D(filters=128, kernel_size=3, strides=1, padding='same', activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Conv2D(filters=64, kernel_size=3, strides=1, padding='same', activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Conv2D(filters=32, kernel_size=3, strides=1, padding='same', activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
# Flatten the feature map
model.add(Flatten())

# Add fully connected layers
model.add(Dense(128, activation='relu'))
model.add(Dropout(0.25))
model.add(Dense(128, activation='relu'))
model.add(Dense(len(class_map), activation='softmax'))  # Output layer

# Print model summary
model.summary()

# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
# Fit the model with early stopping
early_stopping = EarlyStopping(patience=10, restore_best_weights=True)
history = model.fit(
    train_generator,
    epochs=100,
    verbose=1,
    validation_data=val_generator,
    callbacks=[early_stopping])

# Save the model
model.save('/content/drive/My Drive/sports_classification_model.h5')
# Plot loss and accuracy
plt.figure(figsize=(12, 6))
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Loss / Accuracy')
plt.legend()
plt.show()

# Evaluate the model on the test set
loss, accuracy = model.evaluate(test_generator)
print(f"Test Loss: {loss:.4f}")
print(f"Test Accuracy: {accuracy:.4f}")
# Function to generate predictions for a test image
def generate_predictions(test_image_path, actual_label):
  # Load and preprocess the image
    img = load_img(test_image_path, target_size=(150, 150))
    img_arr = img_to_array(img) / 255.0
    img_input = np.expand_dims(img_arr, axis=0) # Reshape to add batch dimension
    # Make predictions
    prediction = model.predict(img_input)[0]
    predicted_label = class_map[np.argmax(prediction)]
    # Plot the image and prediction
    plt.figure(figsize=(6, 6))
    plt.imshow(img_arr)
    plt.title(f"Predicted: {predicted_label}, Actual: {actual_label}")
    plt.axis('off')
    plt.show()
# Test the function with a sample image
test_image_path = '/content/drive/My Drive/sports_classification/test/boxing/3.jpg'
# Call the function to generate predictions
generate_predictions(test_image_path, actual_label='boxing')
